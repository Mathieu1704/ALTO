from fastapi import FastAPI, UploadFile, File, Request, Form
from fastapi.responses import JSONResponse
import tempfile
import os
import base64
from app.utils import transcribe_audio, ask_gpt, synthesize_speech # Assurez-vous que ce chemin est correct

app = FastAPI()

@app.post("/process-voice")
async def process_voice(
    file: UploadFile = File(...),
    lat: float = Form(None), # Latitude de l'utilisateur
    lng: float = Form(None)  # Longitude de l'utilisateur
):
    # 1. Enregistrer temporairement le fichier audio re√ßu
    # Utilisation d'un suffixe plus g√©n√©rique si le format peut varier, bien que Whisper s'attende √† des formats courants.
    # Si vous √™tes s√ªr que c'est du .wav, vous pouvez garder .wav
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".tmpaudio") as tmp:
            content = await file.read()
            tmp.write(content)
            temp_audio_path = tmp.name
    except Exception as e:
        print(f"Erreur lors de la lecture ou sauvegarde du fichier upload√©: {e}")
        return JSONResponse(status_code=500, content={"error": "Erreur traitement fichier audio"})

    # 2. Transcrire l'audio en texte
    user_transcript = "" # Initialiser au cas o√π la transcription √©choue
    try:
        user_transcript = await transcribe_audio(temp_audio_path)
        print(f"üéôÔ∏è Transcrit : {user_transcript}")
        if not user_transcript: # Si la transcription est vide (ex: silence)
            print("‚ö†Ô∏è Transcription vide, peut-√™tre un silence.")
            # Vous pourriez vouloir g√©rer ce cas sp√©cifiquement, ex: retourner un message "Je n'ai rien entendu"
            # Pour l'instant, on laisse ask_gpt g√©rer une cha√Æne vide si c'est le cas.
    except Exception as e:
        print(f"Erreur de transcription: {e}")
        os.remove(temp_audio_path) # Nettoyer le fichier temporaire
        return JSONResponse(status_code=500, content={"error": "Erreur de transcription audio"})

    # 3. Envoyer le texte transcrit (et la g√©olocalisation) √† GPT pour obtenir une r√©ponse
    assistant_response_data = None
    try:
        # MODIFI√â: ask_gpt retourne maintenant un dictionnaire plus structur√©
        assistant_response_data = await ask_gpt(user_transcript, lat=lat, lng=lng)
        
        # Extraire le texte de la r√©ponse et les donn√©es d'action
        assistant_text_response = assistant_response_data.get("text_response")
        action_data = assistant_response_data.get("action_data") # Peut √™tre None

        if not assistant_text_response and not action_data:
            # Si ask_gpt retourne une r√©ponse invalide ou vide sans action
            print("‚ö†Ô∏è R√©ponse vide ou invalide de ask_gpt.")
            assistant_text_response = "Je ne sais pas quoi r√©pondre √† cela." # R√©ponse par d√©faut
        elif not assistant_text_response and action_data:
            # Si il y a une action mais pas de texte (ex: "Ok." implicite)
            assistant_text_response = "Ok." # Ou un autre texte par d√©faut pour l'action

        print(f"ü§ñ R√©ponse de l'assistant (texte) : {assistant_text_response}")
        if action_data:
            print(f"üé¨ Action de l'assistant : {action_data}")

    except Exception as e:
        print(f"Erreur lors de l'appel √† ask_gpt: {e}")
        os.remove(temp_audio_path)
        # Retourner une erreur g√©n√©rique que le client peut vocaliser
        error_message_for_tts = "D√©sol√©, une erreur interne est survenue."
        mp3_path_error = await synthesize_speech(error_message_for_tts)
        audio_base64_error = ""
        if mp3_path_error:
            with open(mp3_path_error, "rb") as f_error:
                audio_base64_error = base64.b64encode(f_error.read()).decode("utf-8")
            os.remove(mp3_path_error)
        
        return JSONResponse(
            status_code=500, 
            content={
                "transcript": user_transcript,
                "response": error_message_for_tts,
                "audio": audio_base64_error,
                "action_data": None # Pas d'action en cas d'erreur
            }
        )

    # 4. Synth√©tiser la r√©ponse textuelle de l'assistant en audio
    mp3_path_response = None
    audio_base64_response = ""
    try:
        if assistant_text_response: # Ne synth√©tiser que s'il y a du texte
            mp3_path_response = await synthesize_speech(assistant_text_response)
            if mp3_path_response:
                with open(mp3_path_response, "rb") as f:
                    audio_base64_response = base64.b64encode(f.read()).decode("utf-8")
                os.remove(mp3_path_response) # Nettoyer le fichier MP3 temporaire
            else:
                print("‚ö†Ô∏è La synth√®se vocale n'a pas retourn√© de chemin de fichier.")
                # Peut-√™tre fournir un audio pr√©-enregistr√© d'erreur de TTS ? Ou laisser vide.
        else:
            print("‚ÑπÔ∏è Pas de texte √† synth√©tiser pour la r√©ponse vocale.")

    except Exception as e:
        print(f"Erreur de synth√®se vocale: {e}")
        # Si la synth√®se √©choue, on envoie quand m√™me le texte et l'action, mais sans audio.
        # Le client devra g√©rer l'absence d'audio.
        # On pourrait aussi tenter de synth√©tiser un message d'erreur ici.

    # 5. Nettoyer le fichier audio d'entr√©e initial
    os.remove(temp_audio_path)

    # 6. Retourner la r√©ponse JSON au client
    # MODIFI√â: Inclure la nouvelle structure de r√©ponse
    return JSONResponse(content={
        "transcript": user_transcript,
        "response_text": assistant_text_response, # Renomm√© pour clart√© (√©tait "response")
        "audio_base64": audio_base64_response,    # Renomm√© pour clart√© (√©tait "audio")
        "action_data": action_data                # Nouvelle cl√© pour les actions client
    })


@app.post("/tts-only")
async def tts_only(request: Request):
    try:
        data = await request.json()
        text_to_synthesize = data.get("text", "")

        if not text_to_synthesize.strip():
            return JSONResponse(status_code=400, content={"error": "Le texte √† synth√©tiser ne peut pas √™tre vide."})

        mp3_path = await synthesize_speech(text_to_synthesize)
        if not mp3_path:
            return JSONResponse(status_code=500, content={"error": "Erreur lors de la synth√®se vocale, aucun fichier audio g√©n√©r√©."})

        with open(mp3_path, "rb") as f:
            audio_base64 = base64.b64encode(f.read()).decode("utf-8")
        os.remove(mp3_path)

        return {"audio_base64": audio_base64} # MODIFI√â: pour coh√©rence
    except Exception as e:
        print(f"Erreur dans tts-only: {e}")
        return JSONResponse(status_code=500, content={"error": f"Erreur interne du serveur: {str(e)}"})


@app.post("/transcribe-only")
async def transcribe_only(file: UploadFile = File(...)):
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".tmpaudio") as tmp:
            content = await file.read()
            tmp.write(content)
            temp_path = tmp.name

        transcript_text = await transcribe_audio(temp_path) # MODIFI√â: pour coh√©rence
        os.remove(temp_path)

        return {"transcript_text": transcript_text} # MODIFI√â: pour coh√©rence
    except Exception as e:
        print(f"Erreur dans transcribe-only: {e}")
        return JSONResponse(status_code=500, content={"error": f"Erreur interne du serveur: {str(e)}"})